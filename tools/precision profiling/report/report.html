<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<title>Accuracy of Machine Learning Kernals</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7952 2016-07-26 18:15:59Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

.subscript {
  vertical-align: sub;
  font-size: smaller }

.superscript {
  vertical-align: super;
  font-size: smaller }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left, table.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right, table.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

table.align-center {
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

.align-top    {
  vertical-align: top }

.align-middle {
  vertical-align: middle }

.align-bottom {
  vertical-align: bottom }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="accuracy-of-machine-learning-kernals">
<h1 class="title">Accuracy of Machine Learning Kernals</h1>

<p>As the process of optimising a model for the xcore applies a quantisation and
changes the operators used, it is important to measure the precision of this
optimised model to ensure it still meets the required precision.</p>
<p>This document will discuss a method for measuring this precision, and comparing
it to that of equivalent tensorflow and tensorflow lite models. For comparison
the model used is a MobileNetV1 model with an Alpha parameter of 0.25, and an
input image dimensionality of 224 x 224 x 3.</p>
<div class="section" id="method">
<h1>Method</h1>
<p>The precision of an xcore model is calculated by comparing the results it produces
to that of the equivalent tensorflow and tensorflow lite models. This is done for
every layer in a given model. This process is detailed below.</p>
<div class="section" id="step-1-generate-a-tensorflow-model">
<h2>Step 1: Generate a tensorflow model</h2>
<p>The first step is to produce a tensorflow base model from Keras. This model will
be the model that the tflite and xcore models are derived from, and will act as a
precision baseline for comparison.</p>
<p>In this case a MobileNetV1 model with an Alpha of 0.25 and a 224x224x3 input image
resolution was generated. Any model that is trained with imagenet weights can be
generated here.</p>
</div>
<div class="section" id="step-2-seperate-model-by-layer">
<h2>Step 2: Seperate Model by layer</h2>
<p>The next step is to seperate the tensorflow model up into it's different layers
and create a tensorflow model for each layer. Some layers such as relus, batch norms,
and dropouts are combined with the convolution layer before them as this is really
part of running the convolution and do not make sense on their own.</p>
</div>
<div class="section" id="step-3-convert-to-tensorflow-lite">
<h2>Step 3: Convert to tensorflow lite</h2>
<p>Keras has built in functionality for converting Keras tensorflow models into
tensorflow lite models. This process however requires a representative dataset to
be generated for each model.</p>
<p>As the model in question is trained with imagenet weights, imagenet_v2 images are
loaded from tensorflow datasets and are used to form a representative dataset for
the input layer (layer 0). In this case a sample of 500 images from imagenet_v2
was used.</p>
<p>A representative dataset is then generated for each subsequent layer. This is
done by using a model made up of the first layer, and every layer up to the target
layer combined. This model is then used to generate predictions for each image
in the original representative dataset, to create a representative dataset of size
500 for each layer.</p>
<p>Once each layer has an associated representative datasset, it can be converted to
a tensorflow lite model. This is an intermediary step to converting to an xcore
model, and can be used as a precision comparison.</p>
</div>
<div class="section" id="step-4-convert-to-xcore">
<h2>Step 4: Convert to xcore</h2>
<p>Finally for each layer, the tensorflow lite model associated can be converted
into an xcore optimised model using the xcore-opt command line tool.</p>
</div>
<div class="section" id="step-5-evaluate-tensorflow-tensorflow-lite-and-xcore-models">
<h2>Step 5: Evaluate tensorflow, tensorflow lite and xcore models</h2>
<p>This stage involves using the representative dataset from each layer, and running
each image through three models associated with that layer to generate 3x500
outputs. This is done so that we have a large sample of outputs from each model
so that the models can be compared more effecively.</p>
</div>
</div>
<div class="section" id="comparison">
<h1>Comparison</h1>
<p>In order to compare the three models, a number of metrics are calculated. These
are calculated between tensorflow and tflite, tensorflow and xcore, and tflite
and xcore models. The metrics calculated are:</p>
<ul class="simple">
<li>Average Error</li>
<li>Average Absolute Error</li>
<li>Max Absolute Error</li>
<li>Mean Squared Error</li>
<li>A Histogram of Average Errors</li>
</ul>
<p>For this comparison, the results of the tensorflow model are quantised so
that they can be directly compared with the outputs of the two quantised
models. This quantisation has a range between (-128, 127) for any value.</p>
<p>For each error, the first graph contains the metric for tensorflow and
tensorflow lite, plotted along with that for tensorflow and xcore. The
second plot displays the metric for tensorflow lite and xcore.</p>
<div class="section" id="average-error">
<h2>Average Error</h2>
<p><img alt="avg1" src="./tf_quant_average.png" style="width: 500px;" />       <img alt="avg2" src="./tflite_xcore_average.png" style="width: 500px;" /></p>
<p>In terms of average error, for most layers in this model the quantised
models are very similar to the tensorflow model. The error is slightly
higher in layers at the start, and the xcore model has a large error
in layer 29.</p>
<p>More interestingly, the xcore and tflite models are almost identical
in this metric, other than in layers 4, 6, and 29 where there are large
divergences.</p>
</div>
<div class="section" id="average-absolute-error">
<h2>Average Absolute Error</h2>
<p><img alt="avgabs1" src="./tf_quant_absolute.png" style="width: 500px;" />       <img alt="avgabs2" src="./tflite_xcore_absolute.png" style="width: 500px;" /></p>
<p>With the Average Absolute Error, we see a higher error in a lot of the
layers for the tensorflow comparison, as these errors would have been
hidden postive and negative errors for the previous metric. The tflite and
xcore comparisons with tensorflow here are very simlar, with some
variation around the problem layers identified in the Average Error.</p>
<p>The tflite vs xcore comparison shows a similar pattern to Average Error,
with spikes in the same layers, and a higher baseline error throughout.</p>
</div>
<div class="section" id="maximum-absolute-error">
<h2>Maximum Absolute Error</h2>
<p><img alt="maxabs1" src="./tf_quant_maximum_absolute.png" style="width: 500px;" />       <img alt="maxabs2" src="./tflite_xcore_maximum_absolute.png" style="width: 500px;" /></p>
<p>The Maximum Absolute Error can bring attention to any large element specific
errors that are masked by averages. Here we see that compared to tensorflow,
the tflite and xcore models have idential Max Absolute Error, except for a
small difference in layer 4. Overall these quantised models have
significant Max Errors for each layer, with a big error in layer 30.</p>
<p>When comparing the two quantised models directly, we see that for most layers
the Maximum Absolute Error is great with values of 0 or 1. There are 2 layers
that have higher errors however, in layers 6 and 29.</p>
</div>
<div class="section" id="mean-squared-error">
<h2>Mean Squared Error</h2>
<p><img alt="mse1" src="./tf_quant_mean_squared.png" style="width: 500px;" />       <img alt="mse2" src="./tflite_xcore_mean_squared.png" style="width: 500px;" /></p>
<p>The Mean Squared Error gives us similar results as shown by the Average Absolute
Error. It will suppress the layers with smaller errors, and accentuates the spikes
we saw. When comparing tensorflow to the quantised models, this makes the errors
in layers 6 and 30 stand out. And in the tflite vs xcore graph the differences in
layers 4, 6 and 29 are amplified.</p>
</div>
<div class="section" id="average-error-histograms">
<h2>Average Error Histograms</h2>
<p>There are a large number of histograms produced, as 3 are created per layer. One
for tf - tflite average error, one for tf - xcore, and one for tflite - xcore.
These histograms take all the individual output errors from a layer and place
them in bins of size 0.2 between -2.1 and 2.1. The frequency for each bin is
plotted as a histogram.</p>
<p><img alt="hist34a" src="./tf_tflite_34.png" style="width: 500px;" />  <img alt="hist34b" src="./tf_xcore_34.png" style="width: 500px;" />  <img alt="hist34c" src="./tflite_xcore_34.png" style="width: 500px;" /></p>
<p>As there are so many histograms, the final layer will be focused on. In the
first two histograms, displaying errors between the tensorflow model and
the quantised models, the distribution of errors is almost identical. With
a large number of errors around zero, and lots of errors at plus and minus
1. There is also a cluster of errors in the -2 region. The tflite - xcore
histogram however shows very few large errors, with most elements having
an error inthe -0.1 - 0.1 region, with a small number of errors around
the -1 region.</p>
<p>If we then plot the histograms of the layers that displayed higher errors
in earlier graphs, 4, 6, and 29.</p>
<p><img alt="hist4a" src="./tf_tflite_4.png" style="width: 500px;" />  <img alt="hist4b" src="./tf_xcore_4.png" style="width: 500px;" />  <img alt="hist4c" src="./tflite_xcore_4.png" style="width: 500px;" /></p>
<p><img alt="hist6a" src="./tf_tflite_6.png" style="width: 500px;" />  <img alt="hist6b" src="./tf_xcore_6.png" style="width: 500px;" />  <img alt="hist6c" src="./tflite_xcore_6.png" style="width: 500px;" /></p>
<p><img alt="hist29a" src="./tf_tflite_29.png" style="width: 500px;" />  <img alt="hist29b" src="./tf_xcore_29.png" style="width: 500px;" />  <img alt="hist29c" src="./tflite_xcore_29.png" style="width: 500px;" /></p>
</div>
</div>
</div>
</body>
</html>
